import psycopg2
import json
from sqlalchemy import create_engine, text
import pandas as pd
from table_for_predicting import processing_work_table
from psycopg2 import OperationalError, sql

def get_date():
    cursor.execute("SELECT table_name FROM information_schema.tables WHERE table_schema = 'public';")

    tables = cursor.fetchall()
    return tables


def read_table_from_postgres(table_name):
    try:
        query = f'SELECT * FROM "{table_name}";'
        cursor.execute(query)
        df = cursor.fetchall()
        return df
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")


def save_dataframe_to_db(df, table_name, db_uri):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç DataFrame –≤ PostgreSQL —Å –ø–æ–º–æ—â—å—é SQLAlchemy.

    :param df: pandas.DataFrame ‚Äì –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    :param table_name: str ‚Äì –∏–º—è —Ç–∞–±–ª–∏—Ü—ã
    :param db_uri: str ‚Äì —Å—Ç—Ä–æ–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è SQLAlchemy (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'postgresql://user:pass@host/dbname')
    """
    engine = create_engine(db_uri)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É, —Å–æ–∑–¥–∞–≤–∞—è —Ç–∞–±–ª–∏—Ü—É –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    df.to_sql(table_name, engine, if_exists='replace', index=False)



def save_tables(csv_file_path, end_name):
    # –ü–æ–ª—É—á–∞–µ–º –∏–º—è —Ç–∞–±–ª–∏—Ü—ã –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    # table_name = os.path.splitext(os.path.basename(csv_file_path))[0]
    table_name = end_name

    # –ó–∞–≥—Ä—É–∂–∞–µ–º CSV –≤ DataFrame
    df = pd.read_csv(csv_file_path)

    # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ CSV (–≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ)
    columns = df.columns
    create_table_query = sql.SQL("""
        CREATE TABLE IF NOT EXISTS {table} (
            {fields}
        );
    """).format(
        table=sql.Identifier(table_name),
        fields=sql.SQL(', ').join(
            sql.SQL("{} TEXT").format(sql.Identifier(col)) for col in columns
        )
    )
    cursor.execute(create_table_query)

    # –í—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏
    for _, row in df.iterrows():
        insert_query = sql.SQL("""
            INSERT INTO {table} ({fields}) VALUES ({placeholders});
        """).format(
            table=sql.Identifier(table_name),
            fields=sql.SQL(', ').join(map(sql.Identifier, columns)),
            placeholders=sql.SQL(', ').join(sql.Placeholder() * len(columns))
        )
        cursor.execute(insert_query, tuple(str(v) for v in row))

    conn.commit()


def create_work_table(db_uri):
    # –ü–æ–ª—É—á–∞–µ–º DataFrame
    df = processing_work_table()

    # –ü—Ä–∏–≤–æ–¥–∏–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫ —Å—Ç—Ä–æ–∫–∞–º (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    df = df.astype(str)

    table_name = 'working_table'
    engine = create_engine(db_uri)

    # –£–¥–∞–ª—è–µ–º —Ç–∞–±–ª–∏—Ü—É –≤—Ä—É—á–Ω—É—é (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å if_exists='replace')
    with engine.connect() as connection:
        connection.execute(text(f'DROP TABLE IF EXISTS {table_name};'))
        print('second')

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º DataFrame –≤ –±–∞–∑—É
    df.to_sql(table_name, engine, if_exists='replace', index=False)
    print("–¢–∞–±–ª–∏—Ü–∞ working_table —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∞.")



def drop_table_from_postgres(table_name):
    # SQL-–∑–∞–ø—Ä–æ—Å: —É–¥–∞–ª–∏—Ç—å —Ç–∞–±–ª–∏—Ü—É, –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    drop_query = sql.SQL("DROP TABLE IF EXISTS {table} CASCADE;").format(
        table=sql.Identifier(table_name)
    )
    cursor.execute(drop_query)
    conn.commit()


if __name__ == "__main__":
    with open('data/database_user.json') as file:
        file_json_data = json.load(file)
    try:
        conn = psycopg2.connect(
            host=file_json_data['host'],
            user=file_json_data['user'],
            port=file_json_data['port'],
            password=file_json_data['password'],
            database=file_json_data['database']
        )
        cursor = conn.cursor()
        # drop_table_from_postgres('serious_table')
        # save_tables('data/working_table.csv', 'working_table')
        for i in read_table_from_postgres('working_table'):
            print(i)
        # create_work_table('postgresql://postgres:ZEcOwNDTbOQDjLHchZKyhEOeEOfnEcFW@switchyard.proxy.rlwy.net:44380/railway')
        # save_dataframe_to_db(
        #     'data/working_table.csv',
        #     'working_table',
        #     'postgresql://postgres:ZEcOwNDTbOQDjLHchZKyhEOeEOfnEcFW@switchyard.proxy.rlwy.net:44380/railway')
    except OperationalError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
    # finally:
    #     cursor.close()
    #     conn.close()
    #     print("üîí –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–∫—Ä—ã—Ç–æ")